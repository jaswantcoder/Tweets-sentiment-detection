import numpy as np
import pandas as pd
from tqdm import tqdm

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from scipy.sparse import hstack
from nltk import word_tokenize
from nltk.corpus import stopwords
from nltk import punkt
stop_words = stopwords.words('english')

class_names = ['label']



# splitting dataframe by row index
train = data.iloc[:136838,:]
test = data.iloc[136839:,:]
"""train = data.iloc[:]

train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip/train.csv').fillna(' ')
test = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv').fillna(' ')"""

train_text = train['text']
test_text = test['text']
all_text = pd.concat([train_text, test_text])

print("Checkpoint1 - Data Read Complete")

embeddings_index = {}
f = open('/content/drive/MyDrive/finalyearproject/glove_twitter_27B/glove.twitter.27B.100d.txt', encoding="utf8")
for line in tqdm(f):
    values = line.split()
    word = values[0]
    try:
       coefs = np.asarray(values[1:], dtype='float32')
       embeddings_index[word] = coefs
    except ValueError:
       pass
f.close()
print('Found %s word vectors.' % len(embeddings_index))
# this function creates a normalized vector for the whole sentence
def sent2vec(s):
    words = str(s).lower()
    words = word_tokenize(words)
    words = [w for w in words if not w in stop_words]
    words = [w for w in words if w.isalpha()]
    M = []
    for w in words:
        try:
            M.append(embeddings_index[w])
        except:
            continue
    M = np.array(M)
    v = M.sum(axis=0)
    if type(v) != np.ndarray:
        return np.zeros(100)
    return v / np.sqrt((v ** 2).sum())

# create sentence vectors using the above function for training and validation set
xtrain_glove = [sent2vec(x) for x in tqdm(train_text)]
xtest_glove = [sent2vec(x) for x in tqdm(test_text)]

print('Checkpoint2 -Normalized Vector for Sentences are created')

xtrain_glove = np.array(xtrain_glove)
xtest_glove = np.array(xtest_glove)

scores = []
#submission = pd.DataFrame.from_dict({'id': test_['label']})
for class_name in class_names:
    train_target = train[class_name]
    classifier = LogisticRegression(solver='sag')

    cv_score = np.mean(cross_val_score(classifier, xtrain_glove, train_target, cv=3, scoring='roc_auc'))
    scores.append(cv_score)
    print('CV score for class {} is {}'.format(class_name, cv_score))

    classifier.fit(xtrain_glove, train_target)
    print('Training LogisticRegression Classifier for {} is complete!!'.format(class_name))
    classifier.predict_proba(xtest_glove)[:, 1]

print('Total CV score is {}'.format(np.mean(scores)))

#submission.to_csv('submission_glove_LogisticRegression.csv', index=False)
